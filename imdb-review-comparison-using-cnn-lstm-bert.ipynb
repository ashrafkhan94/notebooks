{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\n\nimport numpy as np \nimport pandas as pd \n\nimport os\nfrom pathlib import Path\n\nimport plotly.offline as plty\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nimport plotly.figure_factory as ff\n\nfrom wordcloud import WordCloud\nimport plotly.express as px\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.metrics import confusion_matrix\nfrom colorama import Fore, Back, Style, init\n\nfrom tqdm import tqdm\ntqdm.pandas()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-24T04:43:17.236606Z","iopub.execute_input":"2021-10-24T04:43:17.236993Z","iopub.status.idle":"2021-10-24T04:43:21.228284Z","shell.execute_reply.started":"2021-10-24T04:43:17.236871Z","shell.execute_reply":"2021-10-24T04:43:21.227367Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!pip install -q pyspellchecker","metadata":{"execution":{"iopub.status.busy":"2021-10-24T04:43:31.031314Z","iopub.execute_input":"2021-10-24T04:43:31.031817Z","iopub.status.idle":"2021-10-24T04:43:39.623720Z","shell.execute_reply.started":"2021-10-24T04:43:31.031771Z","shell.execute_reply":"2021-10-24T04:43:39.622890Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"PATH = Path('/kaggle/input/imdb-dataset-of-50k-movie-reviews/')\n\ndata = pd.read_csv(PATH / 'IMDB Dataset.csv')","metadata":{"execution":{"iopub.status.busy":"2021-10-24T04:43:39.627058Z","iopub.execute_input":"2021-10-24T04:43:39.627288Z","iopub.status.idle":"2021-10-24T04:43:41.304557Z","shell.execute_reply.started":"2021-10-24T04:43:39.627264Z","shell.execute_reply":"2021-10-24T04:43:41.303859Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"data.info()","metadata":{"execution":{"iopub.status.busy":"2021-10-24T04:43:54.374376Z","iopub.execute_input":"2021-10-24T04:43:54.374642Z","iopub.status.idle":"2021-10-24T04:43:54.414335Z","shell.execute_reply.started":"2021-10-24T04:43:54.374612Z","shell.execute_reply":"2021-10-24T04:43:54.413239Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"data.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-10-23T17:43:23.389631Z","iopub.execute_input":"2021-10-23T17:43:23.390609Z","iopub.status.idle":"2021-10-23T17:43:23.407398Z","shell.execute_reply.started":"2021-10-23T17:43:23.390556Z","shell.execute_reply":"2021-10-23T17:43:23.406757Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"### Mapping Sentiments to Numbers","metadata":{}},{"cell_type":"code","source":"data['sentiment'] = data['sentiment'].map({'positive' : 0, 'negative' : 1})","metadata":{"execution":{"iopub.status.busy":"2021-10-24T04:44:02.583488Z","iopub.execute_input":"2021-10-24T04:44:02.583773Z","iopub.status.idle":"2021-10-24T04:44:02.598465Z","shell.execute_reply.started":"2021-10-24T04:44:02.583741Z","shell.execute_reply":"2021-10-24T04:44:02.597547Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"### Text Preprocessing","metadata":{}},{"cell_type":"code","source":"from spellchecker import SpellChecker\nimport spacy\nimport string, re\n\nspell = SpellChecker()\nPUNCT_TO_REMOVE = string.punctuation\n\ndef remove_punctuation(text):    \n    return text.translate(str.maketrans('', '', PUNCT_TO_REMOVE))\n\n\ndef correct_spellings(text): \n    corrected_text = []\n    misspelled_words = spell.unknown(text.split())\n    for word in text.split():\n        if word in misspelled_words:\n            corrected_text.append(spell.correction(word))\n        else:\n            corrected_text.append(word)\n    return \" \".join(corrected_text)\n\n\ndef remove_urls(text):\n    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n    return url_pattern.sub(r'', text)\n\ndef remove_html(text):\n    html_pattern = re.compile('<.*?>')\n    return html_pattern.sub(r'', text)","metadata":{"execution":{"iopub.status.busy":"2021-10-24T04:44:05.122894Z","iopub.execute_input":"2021-10-24T04:44:05.123363Z","iopub.status.idle":"2021-10-24T04:44:13.052843Z","shell.execute_reply.started":"2021-10-24T04:44:05.123328Z","shell.execute_reply":"2021-10-24T04:44:13.052093Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def clean_text(text):\n    \n    # Lower Casing\n    text = text.lower()\n    \n    # Remove url\n    text = remove_urls(text) \n    \n    # Remove html tags\n    text = remove_html(text)\n    \n    # Removing @tags\n    text = re.sub('@\\w*','',text)\n    \n    # Removing Punctuations\n    text = remove_punctuation(text)\n    \n    # Removing new lines\n    text = re.sub('\\\\n',' ',text)\n    \n    # Correct spellings\n    #text = correct_spellings(text)      \n    \n    return text","metadata":{"execution":{"iopub.status.busy":"2021-10-24T04:44:13.054487Z","iopub.execute_input":"2021-10-24T04:44:13.054737Z","iopub.status.idle":"2021-10-24T04:44:13.060720Z","shell.execute_reply.started":"2021-10-24T04:44:13.054700Z","shell.execute_reply":"2021-10-24T04:44:13.059949Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"data[\"clean_text\"] = data[\"review\"].progress_apply(lambda text: clean_text(text))","metadata":{"execution":{"iopub.status.busy":"2021-10-24T04:44:14.840527Z","iopub.execute_input":"2021-10-24T04:44:14.841096Z","iopub.status.idle":"2021-10-24T04:44:18.238687Z","shell.execute_reply.started":"2021-10-24T04:44:14.841051Z","shell.execute_reply":"2021-10-24T04:44:18.237983Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"data[['review','clean_text']].head(10)","metadata":{"execution":{"iopub.status.busy":"2021-10-23T17:34:43.778462Z","iopub.execute_input":"2021-10-23T17:34:43.779522Z","iopub.status.idle":"2021-10-23T17:34:43.799928Z","shell.execute_reply.started":"2021-10-23T17:34:43.779461Z","shell.execute_reply":"2021-10-23T17:34:43.798897Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"string = ' '.join(data['clean_text'])\n\nwordcloud = WordCloud(max_font_size=None, background_color='black', collocations=False,\n                      width=1200, height=1000).generate(string.lower())\nfig = px.imshow(wordcloud)\nfig.update_layout(title_text='Common words in comments')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-10-23T17:32:00.060978Z","iopub.execute_input":"2021-10-23T17:32:00.061313Z","iopub.status.idle":"2021-10-23T17:32:25.399749Z","shell.execute_reply.started":"2021-10-23T17:32:00.061279Z","shell.execute_reply":"2021-10-23T17:32:25.398760Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"markdown","source":"### Sentiment Analysis","metadata":{}},{"cell_type":"code","source":"import nltk\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\n\ndef polarity(text):\n    if type(text) == str:\n        return SIA.polarity_scores(text)\n    else:\n        return 1000\n    \nSIA = SentimentIntensityAnalyzer()\ndata[\"polarity\"] = data[\"clean_text\"].progress_apply(polarity)","metadata":{"execution":{"iopub.status.busy":"2021-10-23T17:35:08.026177Z","iopub.execute_input":"2021-10-23T17:35:08.026559Z","iopub.status.idle":"2021-10-23T17:38:01.270408Z","shell.execute_reply.started":"2021-10-23T17:35:08.026521Z","shell.execute_reply":"2021-10-23T17:38:01.269410Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"import plotly.graph_objects as go\n\nneg_pol = [pols['neg'] for pols in data[\"polarity\"] if type(pols) is dict]\nneg_pol = list(filter((0.0).__ne__, neg_pol))\n\nfig = go.Figure(go.Histogram(x=neg_pol, marker=dict(\n            color='red')\n    ))\n\nfig.update_layout(xaxis_title=\"Negativity sentiment\", title_text=\"Negativity sentiment\", template=\"simple_white\")\nfig.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-10-23T17:38:03.573914Z","iopub.execute_input":"2021-10-23T17:38:03.574238Z","iopub.status.idle":"2021-10-23T17:38:04.116474Z","shell.execute_reply.started":"2021-10-23T17:38:03.574204Z","shell.execute_reply":"2021-10-23T17:38:04.115863Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"markdown","source":"From the above plot, we can see that negative sentiment has a strong rightward (positive) skew, indicating that negativity is usually on the lower side. This suggests that most comments are not toxic or negative. In fact, the most common negativity value is around 0.14. Virtually no comments have a negativity greater than 0.8.","metadata":{}},{"cell_type":"code","source":"toxic = [x['neg'] for x in data.query(\"sentiment == 1\")['polarity'] if type(x) == dict]\nnon_toxic = [x['neg'] for x in data.query(\"sentiment == 0\")['polarity'] if type(x) == dict]\n\nfig = ff.create_distplot(hist_data=[toxic, non_toxic],\n                         group_labels=[\"Negative\", \"Positive\"],\n                         colors=[\"darkorange\", \"dodgerblue\"], show_hist=False)\n\nfig.update_layout(title_text=\"Negativity of Bad vs Good tweets\", xaxis_title=\"Negativity\", template=\"simple_white\")\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-23T17:38:09.405098Z","iopub.execute_input":"2021-10-23T17:38:09.405727Z","iopub.status.idle":"2021-10-23T17:38:10.879441Z","shell.execute_reply.started":"2021-10-23T17:38:09.405689Z","shell.execute_reply":"2021-10-23T17:38:10.878725Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"markdown","source":"We can clearly see that Neg comments have a significantly greater negative sentiment than Postive comments (on average). The probability density of negativity peaks at around 0 for non-toxic comments, while the negativity for toxic comments at 0.12 . This suggests that a comment is very likely to be non-toxic if it has a negativity of 0.","metadata":{}},{"cell_type":"code","source":"pos_pol = [pols['pos'] for pols in data[\"polarity\"] if type(pols) is dict]\npos_pol = list(filter((0.0).__ne__, pos_pol))\n\nfig = go.Figure(go.Histogram(x=pos_pol, marker=dict(\n            color='seagreen')\n    ))\n\nfig.update_layout(xaxis_title=\"Positivity sentiment\", title_text=\"Positivity sentiment\", template=\"simple_white\")\nfig.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-10-23T17:39:26.377929Z","iopub.execute_input":"2021-10-23T17:39:26.378453Z","iopub.status.idle":"2021-10-23T17:39:26.950688Z","shell.execute_reply.started":"2021-10-23T17:39:26.378401Z","shell.execute_reply":"2021-10-23T17:39:26.949617Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"markdown","source":"Most of the texts are Neutral by Looking at the low postivity & negativity, Let's look at netral values to confirm this","metadata":{}},{"cell_type":"code","source":"neu_pol = [pols['neu'] for pols in data[\"polarity\"] if type(pols) is dict]\nneu_pol = list(filter((1.0).__ne__, neu_pol))\n\nfig = go.Figure(go.Histogram(x=neu_pol, marker=dict(\n            color='darkorange')\n    ))\n\nfig.update_layout(xaxis_title=\"Neutral sentiment\", title_text=\"Neutral sentiment\", template=\"simple_white\")\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-23T17:39:36.030230Z","iopub.execute_input":"2021-10-23T17:39:36.030566Z","iopub.status.idle":"2021-10-23T17:39:36.596088Z","shell.execute_reply.started":"2021-10-23T17:39:36.030532Z","shell.execute_reply":"2021-10-23T17:39:36.594802Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"markdown","source":"From the above plot, we can see that the neutrality sentiment distribution has a strong leftward (negative) skew, which is in constrast to the negativity and positivity sentiment distributions. This indicates that the comments tend to be very neutral and unbiased in general. This also suggests that most comments are not highly opinionated and polarizing, meaning that most comments are non-toxic.","metadata":{}},{"cell_type":"code","source":"total_comments = data['sentiment'].count()\nneg = data['sentiment'].value_counts().loc[1]\nSentiment = ['Negative','Positive']\ncount = [neg, total_comments-neg]\n\nfig = make_subplots(rows=1, cols=2, specs=[[{\"type\": \"bar\"}, {\"type\": \"pie\"}]])\nfig.add_trace(go.Bar(x=Sentiment,y=count,text=count, marker_color=['#D9636B', '#64D9D1']),\n             row=1, col=1)\nfig.add_trace(go.Pie(labels=Sentiment, values=count, domain=dict(x=[0.5, 1.0]), marker_colors=['#D9636B', '#64D9D1']), \n              row=1, col=2)\n\nfig.update_layout(height=600, width=800, title_text=\"Negative vs Postive vs Neutral\", template='plotly_white')\n\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-23T17:39:56.683019Z","iopub.execute_input":"2021-10-23T17:39:56.683367Z","iopub.status.idle":"2021-10-23T17:39:56.788039Z","shell.execute_reply.started":"2021-10-23T17:39:56.683330Z","shell.execute_reply":"2021-10-23T17:39:56.786811Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"string = ' '.join(data.query('sentiment == 1')['clean_text'])\n\nwordcloud = WordCloud(max_font_size=None, background_color='black', collocations=False,\n                      width=1200, height=1000).generate(string.lower())\nfig = px.imshow(wordcloud)\nfig.update_layout(title_text='Negative Reviews')","metadata":{"execution":{"iopub.status.busy":"2021-10-23T17:40:38.075603Z","iopub.execute_input":"2021-10-23T17:40:38.075971Z","iopub.status.idle":"2021-10-23T17:40:50.593342Z","shell.execute_reply.started":"2021-10-23T17:40:38.075932Z","shell.execute_reply":"2021-10-23T17:40:50.592330Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"string = ' '.join(data.query('sentiment == 0')['clean_text'])\n\nwordcloud = WordCloud(max_font_size=None, background_color='black', collocations=False,\n                      width=1200, height=1000).generate(string.lower())\nfig = px.imshow(wordcloud)\nfig.update_layout(title_text='Positive reviews')","metadata":{"execution":{"iopub.status.busy":"2021-10-23T17:41:01.474580Z","iopub.execute_input":"2021-10-23T17:41:01.474967Z","iopub.status.idle":"2021-10-23T17:41:14.270774Z","shell.execute_reply.started":"2021-10-23T17:41:01.474931Z","shell.execute_reply":"2021-10-23T17:41:14.269987Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"import transformers\nimport tensorflow as tf\nfrom tokenizers import BertWordPieceTokenizer\n\nfrom tensorflow.keras.callbacks import Callback\nfrom sklearn.metrics import accuracy_score, roc_auc_score\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, CSVLogger\n\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.layers import Dense, Input, Dropout, Embedding\nfrom tensorflow.keras.layers import LSTM, GRU, Conv1D, SpatialDropout1D\n\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras import activations\nfrom tensorflow.keras import constraints\nfrom tensorflow.keras import initializers\nfrom tensorflow.keras import regularizers\n\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.optimizers import *\nfrom tensorflow.keras.activations import *\nfrom tensorflow.keras.constraints import *\nfrom tensorflow.keras.initializers import *\nfrom tensorflow.keras.regularizers import *","metadata":{"execution":{"iopub.status.busy":"2021-10-24T04:44:44.316057Z","iopub.execute_input":"2021-10-24T04:44:44.316753Z","iopub.status.idle":"2021-10-24T04:44:45.244696Z","shell.execute_reply.started":"2021-10-24T04:44:44.316716Z","shell.execute_reply":"2021-10-24T04:44:45.243979Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"### Bert Tokenizer","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer\ntokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n\nsave_path = '/kaggle/working/distilbert_base_uncased/'\nif not os.path.exists(save_path):\n    os.makedirs(save_path)\ntokenizer.save_pretrained(save_path)","metadata":{"execution":{"iopub.status.busy":"2021-10-24T04:44:47.965601Z","iopub.execute_input":"2021-10-24T04:44:47.965854Z","iopub.status.idle":"2021-10-24T04:44:49.947499Z","shell.execute_reply.started":"2021-10-24T04:44:47.965825Z","shell.execute_reply":"2021-10-24T04:44:49.946738Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"### Encoding","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX, y = data['clean_text'].values,data['sentiment'].values\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, stratify=y, random_state=111)\n\nX_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.125, \n                                                stratify=y_test, random_state=111)","metadata":{"execution":{"iopub.status.busy":"2021-10-24T04:44:53.675190Z","iopub.execute_input":"2021-10-24T04:44:53.675575Z","iopub.status.idle":"2021-10-24T04:44:53.733316Z","shell.execute_reply.started":"2021-10-24T04:44:53.675539Z","shell.execute_reply":"2021-10-24T04:44:53.732430Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"X_train_tokens = tokenizer(list(X_train), padding='max_length', truncation=True, return_tensors=\"tf\")\nX_train_token_ids = X_train_tokens['input_ids']\n\nX_test_tokens = tokenizer(list(X_test), padding='max_length', truncation=True, return_tensors=\"tf\")\nX_test_token_ids = X_test_tokens['input_ids']\n\nX_val_tokens = tokenizer(list(X_val), padding='max_length', truncation=True, return_tensors=\"tf\")\nX_val_token_ids = X_val_tokens['input_ids']","metadata":{"execution":{"iopub.status.busy":"2021-10-24T04:45:05.159718Z","iopub.execute_input":"2021-10-24T04:45:05.160281Z","iopub.status.idle":"2021-10-24T04:45:51.614225Z","shell.execute_reply.started":"2021-10-24T04:45:05.160240Z","shell.execute_reply":"2021-10-24T04:45:51.613435Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"print(X_test_token_ids.shape)\nprint(X_train_token_ids.shape)","metadata":{"execution":{"iopub.status.busy":"2021-10-23T17:45:34.042572Z","iopub.execute_input":"2021-10-23T17:45:34.043065Z","iopub.status.idle":"2021-10-23T17:45:34.048514Z","shell.execute_reply.started":"2021-10-23T17:45:34.043020Z","shell.execute_reply":"2021-10-23T17:45:34.047236Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"## Modelling","metadata":{}},{"cell_type":"markdown","source":"#### Loading the DistilBert Transformer & creating word embeddings","metadata":{}},{"cell_type":"code","source":"# Embedding:\ntransformer = transformers.TFDistilBertModel.\\\n    from_pretrained('distilbert-base-uncased')\nembed = transformer.weights[0].numpy()\n\nprint('Vocab : ', np.shape(embed)[0], 'Hidden States/Embed vector size :', np.shape(embed)[1])","metadata":{"execution":{"iopub.status.busy":"2021-10-24T04:46:14.443857Z","iopub.execute_input":"2021-10-24T04:46:14.444635Z","iopub.status.idle":"2021-10-24T04:46:29.644876Z","shell.execute_reply.started":"2021-10-24T04:46:14.444597Z","shell.execute_reply":"2021-10-24T04:46:29.644144Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"MAX_LEN = 512\nBATCH_SIZE = 12\nSTEPS_PER_EPOCH = X_train_token_ids.shape[0] // BATCH_SIZE","metadata":{"execution":{"iopub.status.busy":"2021-10-24T04:46:29.646416Z","iopub.execute_input":"2021-10-24T04:46:29.646691Z","iopub.status.idle":"2021-10-24T04:46:29.651839Z","shell.execute_reply.started":"2021-10-24T04:46:29.646653Z","shell.execute_reply":"2021-10-24T04:46:29.651031Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"### Callback","metadata":{}},{"cell_type":"code","source":"reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss',  \n                                    factor=0.3, patience=2, \n                                    verbose=1, mode='auto', \n                                    epsilon=0.0001, cooldown=1, min_lr=0.000001)","metadata":{"execution":{"iopub.status.busy":"2021-10-23T17:46:12.680647Z","iopub.execute_input":"2021-10-23T17:46:12.681194Z","iopub.status.idle":"2021-10-23T17:46:12.685999Z","shell.execute_reply.started":"2021-10-23T17:46:12.681150Z","shell.execute_reply":"2021-10-23T17:46:12.685167Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"### Helper functions","metadata":{}},{"cell_type":"code","source":"def visualize_model_preds(y_pred, indices=[0, 1, 2, 3]):\n\n    for idx, i in enumerate(indices):\n        if y_test[i] == 0:\n            label = \"Non-toxic\"\n            color = f'{Fore.GREEN}'\n            symbol = '\\u2714'\n        else:\n            label = \"Toxic\"\n            color = f'{Fore.RED}'\n            symbol = '\\u2716'\n\n        print('{}{} {}'.format(color, str(idx+1) + \". \" + label, symbol))\n        print(f'{Style.RESET_ALL}')\n\n        print(X_test[idx]); print(\"\")\n        fig = go.Figure()\n        if y_test[i] == 1:\n            yl = [1 - y_pred[i], y_pred[i]]\n            \n        else:\n            yl = [1 - y_pred[i], y_pred[i]]\n\n        fig.add_trace(go.Bar(x=['Positive', 'Negative'], y=yl, marker=dict(color=[\"seagreen\", \"indianred\"])))\n        fig.update_traces(name=X_test[idx])\n        fig.update_layout(xaxis_title=\"Labels\", yaxis_title=\"Probability\", template=\"plotly_white\", title_text=\"Predictions for validation comment #{}\".format(idx+1))\n        fig.show()\n        \ndef plot_cm(y_true, y_pred, title, figsize=(7,6)):\n    y_pred = y_pred.round().astype(int)\n    cm = confusion_matrix(y_true, y_pred, labels=np.unique(y_true))\n    cm_sum = np.sum(cm, axis=1, keepdims=True)\n    cm_perc = cm / cm_sum.astype(float) * 100\n    annot = np.empty_like(cm).astype(str)\n    nrows, ncols = cm.shape\n    for i in range(nrows):\n        for j in range(ncols):\n            c = cm[i, j]\n            p = cm_perc[i, j]\n            if i == j:\n                s = cm_sum[i]\n                annot[i, j] = '%.1f%%\\n%d/%d' % (p, c, s)\n            elif c == 0:\n                annot[i, j] = ''\n            else:\n                annot[i, j] = '%.1f%%\\n%d' % (p, c)\n    cm = pd.DataFrame(cm, index=np.unique(y_true), columns=np.unique(y_true))\n    cm.index.name = 'Actual'\n    cm.columns.name = 'Predicted'\n    fig, ax = plt.subplots(figsize=figsize)\n    plt.title(title)\n    sns.heatmap(cm, cmap= \"YlGnBu\", annot=annot, fmt='', ax=ax)","metadata":{"execution":{"iopub.status.busy":"2021-10-24T05:45:18.324403Z","iopub.execute_input":"2021-10-24T05:45:18.324654Z","iopub.status.idle":"2021-10-24T05:45:18.339457Z","shell.execute_reply.started":"2021-10-24T05:45:18.324625Z","shell.execute_reply":"2021-10-24T05:45:18.338806Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"markdown","source":"### 1. Vanilla neural network","metadata":{}},{"cell_type":"code","source":"def vanilla_model():\n\n    input_word_ids = Input(shape=(MAX_LEN,), dtype=tf.int32, name=\"input_word_ids\")\n\n\n    embedding = Embedding(np.shape(embed)[0], np.shape(embed)[1],\n                              input_length=MAX_LEN, weights=[embed],\n                              trainable=False)(input_word_ids)\n\n    x = K.sum(embedding, axis=2)\n    x = Dense(512, activation='relu')(x)\n    out = Dense(1, activation='sigmoid')(x)\n    \n\n    model = Model(inputs=input_word_ids, outputs=out)\n\n    model.compile(Adam(lr=0.001), \n                      loss='binary_crossentropy', \n                      metrics=['accuracy'])\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-10-23T17:48:21.774866Z","iopub.execute_input":"2021-10-23T17:48:21.775153Z","iopub.status.idle":"2021-10-23T17:48:21.783014Z","shell.execute_reply.started":"2021-10-23T17:48:21.775115Z","shell.execute_reply":"2021-10-23T17:48:21.782284Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"van_model = vanilla_model()\n\ntrain_history = van_model.fit(\n    X_train_token_ids, y_train,\n    steps_per_epoch=STEPS_PER_EPOCH,\n    validation_data=(X_val_token_ids, y_val),\n    epochs=7,\n    callbacks = [reduceLROnPlat]\n)","metadata":{"execution":{"iopub.status.busy":"2021-10-23T17:48:28.482822Z","iopub.execute_input":"2021-10-23T17:48:28.483436Z","iopub.status.idle":"2021-10-23T17:49:11.993692Z","shell.execute_reply.started":"2021-10-23T17:48:28.483394Z","shell.execute_reply":"2021-10-23T17:49:11.992906Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"#### Evaluate & predict","metadata":{}},{"cell_type":"code","source":"van_model.evaluate(X_test_token_ids, y_test)\n\ny_pred = van_model.predict(X_test_token_ids)","metadata":{"execution":{"iopub.status.busy":"2021-10-23T17:49:23.149245Z","iopub.execute_input":"2021-10-23T17:49:23.149787Z","iopub.status.idle":"2021-10-23T17:49:25.214512Z","shell.execute_reply.started":"2021-10-23T17:49:23.149750Z","shell.execute_reply":"2021-10-23T17:49:25.213608Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"### Classifying with probabilty threshold = 0.5","metadata":{}},{"cell_type":"code","source":"y_preds = y_pred > 0.5\ny_preds = np.where(y_preds == True, 1, 0)","metadata":{"execution":{"iopub.status.busy":"2021-10-23T17:49:37.811962Z","iopub.execute_input":"2021-10-23T17:49:37.812916Z","iopub.status.idle":"2021-10-23T17:49:37.818158Z","shell.execute_reply.started":"2021-10-23T17:49:37.812868Z","shell.execute_reply":"2021-10-23T17:49:37.817201Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"plot_cm(y_test, y_preds, 'Threshold=0.5')","metadata":{"execution":{"iopub.status.busy":"2021-10-23T17:49:42.957811Z","iopub.execute_input":"2021-10-23T17:49:42.958572Z","iopub.status.idle":"2021-10-23T17:49:43.243320Z","shell.execute_reply.started":"2021-10-23T17:49:42.958530Z","shell.execute_reply":"2021-10-23T17:49:43.242611Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\nprint(classification_report(y_test, y_preds))","metadata":{"execution":{"iopub.status.busy":"2021-10-23T17:49:54.724184Z","iopub.execute_input":"2021-10-23T17:49:54.725031Z","iopub.status.idle":"2021-10-23T17:49:54.746897Z","shell.execute_reply.started":"2021-10-23T17:49:54.724973Z","shell.execute_reply":"2021-10-23T17:49:54.746066Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"Very Poor Performance acheived from Vanilla network with all the positive classes missclassified.\n\nWe will be adjusting the probabilty threshold using G-Means","metadata":{}},{"cell_type":"markdown","source":"### Probability Threshold Moving : Finding the best Threshold","metadata":{}},{"cell_type":"markdown","source":"We have to search a range of threshold values in order to find the best threshold.\nIn some cases, the optimal threshold can be calculated directly. Tuning or shifting the decision threshold in order to accommodate the broader requirements of the classification problem is generally referred to as threshold-moving, threshold-tuning, or simply thresholding.","metadata":{}},{"cell_type":"markdown","source":"#### ROC curve","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import roc_curve, precision_recall_curve\n\nfpr, tpr, thresholds = roc_curve(y_test, y_pred.reshape(y_test.shape[0]))\ngmeans = np.sqrt(tpr * (1-fpr))\n\n# locate the index of the largest g-mean\nix = np.argmax(gmeans)\n\nprint('Best Threshold=%f, G-mean=%.3f' % (thresholds[ix], gmeans[ix]))","metadata":{"execution":{"iopub.status.busy":"2021-10-23T17:50:22.994785Z","iopub.execute_input":"2021-10-23T17:50:22.995679Z","iopub.status.idle":"2021-10-23T17:50:23.004461Z","shell.execute_reply.started":"2021-10-23T17:50:22.995638Z","shell.execute_reply":"2021-10-23T17:50:23.003315Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"y_preds = y_pred > thresholds[ix]\ny_preds = np.where(y_preds == True, 1, 0)","metadata":{"execution":{"iopub.status.busy":"2021-10-23T17:50:29.326364Z","iopub.execute_input":"2021-10-23T17:50:29.326687Z","iopub.status.idle":"2021-10-23T17:50:29.333613Z","shell.execute_reply.started":"2021-10-23T17:50:29.326650Z","shell.execute_reply":"2021-10-23T17:50:29.332849Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"plot_cm(y_test, y_preds, f'Threshold = {thresholds[ix]}')","metadata":{"execution":{"iopub.status.busy":"2021-10-23T17:50:33.313292Z","iopub.execute_input":"2021-10-23T17:50:33.313551Z","iopub.status.idle":"2021-10-23T17:50:33.560987Z","shell.execute_reply.started":"2021-10-23T17:50:33.313520Z","shell.execute_reply":"2021-10-23T17:50:33.560285Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"Great improvement in the Positve class using Probabilty Threshold moving , but vice versa for Negative class","metadata":{}},{"cell_type":"markdown","source":"### 2. Modelling with CNN","metadata":{}},{"cell_type":"code","source":"def build_cnn_model(max_len=MAX_LEN):\n    input_word_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n    \n    embedding = Embedding(np.shape(embed)[0], np.shape(embed)[1],\n                          input_length=max_len, weights=[embed],\n                          trainable=False)(input_word_ids)\n    \n    embedding = SpatialDropout1D(0.3)(embedding)\n    conv_1 = Conv1D(64, 2)(embedding)\n    conv_2 = Conv1D(64, 3)(embedding)\n    conv_3 = Conv1D(64, 4)(embedding)\n    conv_4 = Conv1D(64, 5)(embedding)\n    \n    maxpool_1 = GlobalAveragePooling1D()(conv_1)\n    maxpool_2 = GlobalAveragePooling1D()(conv_2)\n    maxpool_3 = GlobalAveragePooling1D()(conv_3)\n    maxpool_4 = GlobalAveragePooling1D()(conv_4)\n    conc = concatenate([maxpool_1, maxpool_2, maxpool_3, maxpool_4], axis=1)\n\n    conc = Dense(64, activation='relu')(conc)\n    conc = Dense(1, activation='sigmoid')(conc)\n    \n    model = Model(inputs=input_word_ids, outputs=conc)\n    \n    model.compile(Adam(lr=0.01), \n                  loss='binary_crossentropy', \n                  metrics=['accuracy'])\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2021-10-23T17:52:18.698801Z","iopub.execute_input":"2021-10-23T17:52:18.699100Z","iopub.status.idle":"2021-10-23T17:52:18.708419Z","shell.execute_reply.started":"2021-10-23T17:52:18.699068Z","shell.execute_reply":"2021-10-23T17:52:18.707513Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"cnn_model = build_cnn_model()\n\ntrain_history = cnn_model.fit(\n    X_train_token_ids, y_train,\n    steps_per_epoch=STEPS_PER_EPOCH,\n    validation_data=(X_val_token_ids, y_val),\n    epochs=10,\n    callbacks = [reduceLROnPlat]\n)","metadata":{"execution":{"iopub.status.busy":"2021-10-23T17:52:22.541146Z","iopub.execute_input":"2021-10-23T17:52:22.541700Z","iopub.status.idle":"2021-10-23T17:56:45.214713Z","shell.execute_reply.started":"2021-10-23T17:52:22.541662Z","shell.execute_reply":"2021-10-23T17:56:45.213910Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"### Poor performance from CNN model as well","metadata":{}},{"cell_type":"markdown","source":"### 3. LSTM + Attention Layer","metadata":{}},{"cell_type":"code","source":"class AttentionWeightedAverage(Layer):\n\n    def __init__(self, return_attention=False, **kwargs):\n        self.init = initializers.get('uniform')\n        self.supports_masking = True\n        self.return_attention = return_attention\n        super(AttentionWeightedAverage, self).__init__(** kwargs)\n\n    def build(self, input_shape):\n        self.input_spec = [InputSpec(ndim=3)]\n        assert len(input_shape) == 3\n\n        self.W = self.add_weight(shape=(input_shape[2], 1),\n                                 name='{}_W'.format(self.name),\n                                 initializer=self.init)\n        super(AttentionWeightedAverage, self).build(input_shape)\n\n    def call(self, x, mask=None):\n        logits = K.dot(x, self.W)\n        x_shape = K.shape(x)\n        logits = K.reshape(logits, (x_shape[0], x_shape[1]))\n        ai = K.exp(logits - K.max(logits, axis=-1, keepdims=True))\n\n        if mask is not None:\n            mask = K.cast(mask, K.floatx())\n            ai = ai * mask\n        att_weights = ai / (K.sum(ai, axis=1, keepdims=True) + K.epsilon())\n        weighted_input = x * K.expand_dims(att_weights)\n        result = K.sum(weighted_input, axis=1)\n        if self.return_attention:\n            return [result, att_weights]\n        return result\n\n    def get_output_shape_for(self, input_shape):\n        return self.compute_output_shape(input_shape)\n\n    def compute_output_shape(self, input_shape):\n        output_len = input_shape[2]\n        if self.return_attention:\n            return [(input_shape[0], output_len), (input_shape[0], input_shape[1])]\n        return (input_shape[0], output_len)\n\n    def compute_mask(self, input, input_mask=None):\n        if isinstance(input_mask, list):\n            return [None] * len(input_mask)\n        else:\n            return None","metadata":{"execution":{"iopub.status.busy":"2021-10-23T17:56:46.542552Z","iopub.execute_input":"2021-10-23T17:56:46.542803Z","iopub.status.idle":"2021-10-23T17:56:46.556656Z","shell.execute_reply.started":"2021-10-23T17:56:46.542770Z","shell.execute_reply":"2021-10-23T17:56:46.555904Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"def build_lstm_model(max_len=MAX_LEN):\n    input_word_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n    \n    embed = transformer.weights[0].numpy()\n    embedding = Embedding(np.shape(embed)[0], np.shape(embed)[1],\n                          input_length=max_len, weights=[embed],\n                          trainable=False)(input_word_ids)\n    \n    embedding = SpatialDropout1D(0.3)(embedding)\n    lstm_1 = LSTM(128, return_sequences=True)(embedding)\n    lstm_2 = LSTM(128, return_sequences=True)(lstm_1)\n    \n    attention = AttentionWeightedAverage()(lstm_2)\n    conc = Dense(64, activation='relu')(attention)\n    conc = Dense(1, activation='sigmoid')(conc)\n    \n    model = Model(inputs=input_word_ids, outputs=conc)\n    \n    model.compile(Adam(lr=0.01), \n                  loss='binary_crossentropy', \n                  metrics=['accuracy'])\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2021-10-23T17:56:53.411881Z","iopub.execute_input":"2021-10-23T17:56:53.412467Z","iopub.status.idle":"2021-10-23T17:56:53.420062Z","shell.execute_reply.started":"2021-10-23T17:56:53.412428Z","shell.execute_reply":"2021-10-23T17:56:53.419353Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"lstm_model = build_lstm_model()\n\ntrain_history = lstm_model.fit(\n    X_train_token_ids, y_train,\n    steps_per_epoch=STEPS_PER_EPOCH,\n    validation_data=(X_val_token_ids, y_val),\n    epochs=6,\n    callbacks = [reduceLROnPlat]\n)","metadata":{"execution":{"iopub.status.busy":"2021-10-23T17:57:25.398345Z","iopub.execute_input":"2021-10-23T17:57:25.398610Z","iopub.status.idle":"2021-10-23T18:12:50.649206Z","shell.execute_reply.started":"2021-10-23T17:57:25.398580Z","shell.execute_reply":"2021-10-23T18:12:50.648441Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":"The models using CNN, LSTM & Vanilla network did not perform good at all, these models could not learn the Dataset and performed somewhat same.","metadata":{}},{"cell_type":"markdown","source":"### 4. Bert Transformer","metadata":{}},{"cell_type":"code","source":"bert_transformer = transformers.TFDistilBertModel.\\\n    from_pretrained('distilbert-base-uncased')","metadata":{"execution":{"iopub.status.busy":"2021-10-24T04:48:34.412510Z","iopub.execute_input":"2021-10-24T04:48:34.412780Z","iopub.status.idle":"2021-10-24T04:48:35.228644Z","shell.execute_reply.started":"2021-10-24T04:48:34.412751Z","shell.execute_reply":"2021-10-24T04:48:35.227935Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"y_train = y_train.astype('int32')\ny_test = y_test.astype('int32')\ny_val = y_val.astype('int32')","metadata":{"execution":{"iopub.status.busy":"2021-10-24T04:48:40.272866Z","iopub.execute_input":"2021-10-24T04:48:40.273572Z","iopub.status.idle":"2021-10-24T04:48:40.281783Z","shell.execute_reply.started":"2021-10-24T04:48:40.273540Z","shell.execute_reply":"2021-10-24T04:48:40.280833Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"def build_bert_model(maxlen=MAX_LEN):\n    input_ids = Input(shape=(maxlen,), dtype=tf.int32, name=\"input_word_ids\")\n    embeddings = bert_transformer(input_ids)[0]\n\n    cls_token = embeddings[:, 0, :]\n    x = Dense(maxlen, activation=\"relu\")(cls_token)\n    x = Dropout(0.5)(x)\n    out = Dense(1, activation='sigmoid')(x)\n\n    model = Model(inputs=input_ids, outputs=out)\n\n    model.compile(Adam(learning_rate=1.5e-5), \n                      loss='binary_crossentropy', \n                      metrics=['accuracy'])\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2021-10-24T04:49:59.342245Z","iopub.execute_input":"2021-10-24T04:49:59.342708Z","iopub.status.idle":"2021-10-24T04:49:59.350830Z","shell.execute_reply.started":"2021-10-24T04:49:59.342672Z","shell.execute_reply":"2021-10-24T04:49:59.348526Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"model = build_bert_model()\n\ntrain_history = model.fit(\n    X_train_token_ids, y_train,\n    steps_per_epoch=STEPS_PER_EPOCH,\n    validation_data=(X_val_token_ids, y_val),\n    epochs=2\n)","metadata":{"execution":{"iopub.status.busy":"2021-10-24T04:50:32.312654Z","iopub.execute_input":"2021-10-24T04:50:32.312932Z","iopub.status.idle":"2021-10-24T05:33:04.225221Z","shell.execute_reply.started":"2021-10-24T04:50:32.312888Z","shell.execute_reply":"2021-10-24T05:33:04.224430Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"y_pred = model.predict(X_test_token_ids)","metadata":{"execution":{"iopub.status.busy":"2021-10-24T05:37:21.224452Z","iopub.execute_input":"2021-10-24T05:37:21.224793Z","iopub.status.idle":"2021-10-24T05:39:44.547886Z","shell.execute_reply.started":"2021-10-24T05:37:21.224754Z","shell.execute_reply":"2021-10-24T05:39:44.547069Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"y_pred = y_pred.reshape(y_pred.shape[0])","metadata":{"execution":{"iopub.status.busy":"2021-10-24T05:40:50.128493Z","iopub.execute_input":"2021-10-24T05:40:50.129090Z","iopub.status.idle":"2021-10-24T05:40:50.132913Z","shell.execute_reply.started":"2021-10-24T05:40:50.129052Z","shell.execute_reply":"2021-10-24T05:40:50.132099Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"y_pred[:10]","metadata":{"execution":{"iopub.status.busy":"2021-10-24T05:42:49.378624Z","iopub.execute_input":"2021-10-24T05:42:49.378960Z","iopub.status.idle":"2021-10-24T05:42:49.386138Z","shell.execute_reply.started":"2021-10-24T05:42:49.378889Z","shell.execute_reply":"2021-10-24T05:42:49.385306Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"visualize_model_preds(y_pred)","metadata":{"execution":{"iopub.status.busy":"2021-10-24T05:44:21.978255Z","iopub.execute_input":"2021-10-24T05:44:21.978513Z","iopub.status.idle":"2021-10-24T05:44:22.105038Z","shell.execute_reply.started":"2021-10-24T05:44:21.978477Z","shell.execute_reply":"2021-10-24T05:44:22.104171Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"y_preds = y_pred > 0.5\ny_preds = np.where(y_preds == True, 1, 0)","metadata":{"execution":{"iopub.status.busy":"2021-10-24T05:49:23.805410Z","iopub.execute_input":"2021-10-24T05:49:23.805942Z","iopub.status.idle":"2021-10-24T05:49:23.810153Z","shell.execute_reply.started":"2021-10-24T05:49:23.805889Z","shell.execute_reply":"2021-10-24T05:49:23.809313Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"markdown","source":"### Accuracy","metadata":{}},{"cell_type":"code","source":"old_accuracy = accuracy_score(y_preds, y_test)\nold_accuracy","metadata":{"execution":{"iopub.status.busy":"2021-10-24T05:49:26.076155Z","iopub.execute_input":"2021-10-24T05:49:26.076416Z","iopub.status.idle":"2021-10-24T05:49:26.084080Z","shell.execute_reply.started":"2021-10-24T05:49:26.076389Z","shell.execute_reply":"2021-10-24T05:49:26.083307Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"plot_cm(y_test, y_preds, 'Threshold=0.5')","metadata":{"execution":{"iopub.status.busy":"2021-10-24T05:47:52.639520Z","iopub.execute_input":"2021-10-24T05:47:52.639775Z","iopub.status.idle":"2021-10-24T05:47:52.912054Z","shell.execute_reply.started":"2021-10-24T05:47:52.639748Z","shell.execute_reply":"2021-10-24T05:47:52.911176Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"markdown","source":"### Finding the optimal threshold using ROC-AUC","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import roc_curve\n\nfpr, tpr, thresholds = roc_curve(y_test, y_pred)\ngmeans = np.sqrt(tpr * (1-fpr))\n\n# locate the index of the largest g-mean\nix = np.argmax(gmeans)\n\nprint('Best Threshold=%f, G-mean=%.3f' % (thresholds[ix], gmeans[ix]))","metadata":{"execution":{"iopub.status.busy":"2021-10-24T05:48:08.092647Z","iopub.execute_input":"2021-10-24T05:48:08.093388Z","iopub.status.idle":"2021-10-24T05:48:08.102829Z","shell.execute_reply.started":"2021-10-24T05:48:08.093347Z","shell.execute_reply":"2021-10-24T05:48:08.101974Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.figure(figsize=(10,5))\nplt.plot([0,1], [0,1], linestyle='--', label='No Skill') \n\nplt.plot(fpr, tpr, marker='.', label='Logistic') \nplt.scatter(fpr[ix], tpr[ix], marker='o', color='black', label='Best') \n# axis labels\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.legend()\n# show the plot\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-10-24T05:48:12.245588Z","iopub.execute_input":"2021-10-24T05:48:12.245846Z","iopub.status.idle":"2021-10-24T05:48:12.484400Z","shell.execute_reply.started":"2021-10-24T05:48:12.245815Z","shell.execute_reply":"2021-10-24T05:48:12.483724Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"markdown","source":"### Classifying using optimal threshold","metadata":{}},{"cell_type":"code","source":"y_preds = (y_pred > thresholds[ix])\ny_preds = np.where(y_preds == True, 1, 0)","metadata":{"execution":{"iopub.status.busy":"2021-10-24T05:49:57.626072Z","iopub.execute_input":"2021-10-24T05:49:57.626600Z","iopub.status.idle":"2021-10-24T05:49:57.631317Z","shell.execute_reply.started":"2021-10-24T05:49:57.626565Z","shell.execute_reply":"2021-10-24T05:49:57.630228Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"new_accuracy = accuracy_score(y_preds, y_test)\n\n\nprint(f'Percent increase in accuracy after threshold moving = {((new_accuracy - old_accuracy)/old_accuracy) * 100}')","metadata":{"execution":{"iopub.status.busy":"2021-10-24T05:51:46.921217Z","iopub.execute_input":"2021-10-24T05:51:46.921734Z","iopub.status.idle":"2021-10-24T05:51:46.928594Z","shell.execute_reply.started":"2021-10-24T05:51:46.921700Z","shell.execute_reply":"2021-10-24T05:51:46.927872Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"plot_cm(y_test, y_pred, 'Optimal Threshold')","metadata":{"execution":{"iopub.status.busy":"2021-10-24T05:52:32.244514Z","iopub.execute_input":"2021-10-24T05:52:32.244822Z","iopub.status.idle":"2021-10-24T05:52:32.615729Z","shell.execute_reply.started":"2021-10-24T05:52:32.244788Z","shell.execute_reply":"2021-10-24T05:52:32.615058Z"},"trusted":true},"execution_count":64,"outputs":[]}]}